# intelligent_router.py
"""
LLM-as-a-Judge Intelligent Router
LLM ê¸°ë°˜ ì§€ëŠ¥í˜• ë¼ìš°í„°

ì†Œí˜• ëª¨ë¸ì´ ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ ë¨¼ì € íŒë³„í•œ í›„
ì ì ˆí•œ ëª¨ë¸ë¡œ ë¼ìš°íŒ…í•˜ëŠ” ì§€ëŠ¥í˜• ì‹œìŠ¤í…œ
"""

from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import json
import time
import asyncio

try:
    from .config import MODEL_CONFIGS, TaskComplexity, ModelProvider
except ImportError:
    from config import MODEL_CONFIGS, TaskComplexity, ModelProvider


class ComplexityLevel(Enum):
    """ë³µì¡ë„ ë ˆë²¨ (Complexity Level)"""
    TRIVIAL = 1      # ë‹¨ìˆœ ì‚¬ì‹¤ í™•ì¸, ë²ˆì—­
    SIMPLE = 2       # ê°„ë‹¨í•œ ì§ˆë¬¸ì‘ë‹µ
    MODERATE = 3     # ì¤‘ê°„ ë³µì¡ë„
    COMPLEX = 4      # ë¶„ì„, ì¶”ë¡  í•„ìš”
    EXPERT = 5       # ì „ë¬¸ê°€ ìˆ˜ì¤€, ë‹¤ë‹¨ê³„ ì¶”ë¡ 


@dataclass
class ComplexityAnalysis:
    """ë³µì¡ë„ ë¶„ì„ ê²°ê³¼"""
    level: ComplexityLevel
    confidence: float
    reasoning: str
    recommended_model: str
    estimated_tokens: int
    requires_tools: bool = False
    requires_knowledge: bool = False
    analysis_time_ms: float = 0


@dataclass
class RoutingDecision:
    """ë¼ìš°íŒ… ê²°ì •"""
    selected_model: str
    fallback_model: str
    complexity: ComplexityAnalysis
    strategy: str
    cost_estimate: float
    latency_estimate_ms: int
    decision_time_ms: float


class JudgeLLM:
    """Judge LLM - ë³µì¡ë„ íŒë³„ ì „ìš© ê²½ëŸ‰ ëª¨ë¸
    
    ì‘ì€ ëª¨ë¸(GPT-3.5, Claude Haiku ë“±)ì„ ì‚¬ìš©í•˜ì—¬
    ë¹ ë¥´ê²Œ ì§ˆë¬¸ì˜ ë³µì¡ë„ë¥¼ íŒë³„í•©ë‹ˆë‹¤.
    """
    
    SYSTEM_PROMPT = """You are a query complexity analyzer. Analyze the user's query and classify its complexity.

Output JSON format:
{
    "level": 1-5 (1=trivial, 2=simple, 3=moderate, 4=complex, 5=expert),
    "confidence": 0.0-1.0,
    "reasoning": "Brief explanation",
    "requires_tools": true/false,
    "requires_knowledge": true/false,
    "estimated_response_tokens": number
}

Classification criteria:
- Level 1 (TRIVIAL): Simple facts, translations, basic math
- Level 2 (SIMPLE): One-step Q&A, summaries, formatting
- Level 3 (MODERATE): Multi-step reasoning, explanations
- Level 4 (COMPLEX): Analysis, code generation, creative writing
- Level 5 (EXPERT): Multi-domain expertise, long-form content, research

Be concise. Output only valid JSON."""

    def __init__(self, model: str = "gpt-4o-mini"):
        self.model = model
        self._client = None
    
    def _get_client(self):
        """LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self._client is None:
            try:
                from langchain_openai import ChatOpenAI
                self._client = ChatOpenAI(
                    model=self.model,
                    temperature=0,
                    max_tokens=200
                )
            except Exception:
                self._client = None
        return self._client
    
    async def analyze(self, query: str) -> ComplexityAnalysis:
        """ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„"""
        start_time = time.time()
        
        client = self._get_client()
        
        if client:
            try:
                from langchain_core.messages import SystemMessage, HumanMessage
                
                response = await client.ainvoke([
                    SystemMessage(content=self.SYSTEM_PROMPT),
                    HumanMessage(content=f"Analyze this query: {query}")
                ])
                
                result = json.loads(response.content)
                
                return ComplexityAnalysis(
                    level=ComplexityLevel(result["level"]),
                    confidence=result["confidence"],
                    reasoning=result["reasoning"],
                    recommended_model=self._get_recommended_model(result["level"]),
                    estimated_tokens=result.get("estimated_response_tokens", 500),
                    requires_tools=result.get("requires_tools", False),
                    requires_knowledge=result.get("requires_knowledge", False),
                    analysis_time_ms=(time.time() - start_time) * 1000
                )
            except Exception as e:
                print(f"âš ï¸ Judge LLM error: {e}")
        
        # í´ë°±: íœ´ë¦¬ìŠ¤í‹± ë¶„ì„
        return self._heuristic_analyze(query, start_time)
    
    def _heuristic_analyze(self, query: str, start_time: float) -> ComplexityAnalysis:
        """íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë³µì¡ë„ ë¶„ì„"""
        query_lower = query.lower()
        word_count = len(query.split())
        
        # ë ˆë²¨ ê²°ì •
        level = ComplexityLevel.MODERATE
        confidence = 0.7
        requires_tools = False
        requires_knowledge = False
        
        # TRIVIAL íŒ¨í„´
        trivial_patterns = ["translate", "ë²ˆì—­", "what is", "define", "ë­ì•¼", "ì–¸ì œ"]
        if any(p in query_lower for p in trivial_patterns) and word_count < 15:
            level = ComplexityLevel.TRIVIAL
            confidence = 0.85
        
        # SIMPLE íŒ¨í„´
        simple_patterns = ["summarize", "ìš”ì•½", "list", "how to", "ì–´ë–»ê²Œ"]
        if any(p in query_lower for p in simple_patterns):
            level = ComplexityLevel.SIMPLE
            confidence = 0.8
        
        # COMPLEX íŒ¨í„´
        complex_patterns = [
            "analyze", "ë¶„ì„", "compare", "ë¹„êµ", "code", "ì½”ë“œ",
            "implement", "êµ¬í˜„", "design", "ì„¤ê³„", "algorithm"
        ]
        if any(p in query_lower for p in complex_patterns):
            level = ComplexityLevel.COMPLEX
            confidence = 0.8
            requires_tools = "code" in query_lower or "ì½”ë“œ" in query_lower
        
        # EXPERT íŒ¨í„´
        expert_patterns = [
            "architecture", "ì•„í‚¤í…ì²˜", "system design", "research",
            "optimize", "ìµœì í™”", "strategic", "ì „ëµ", "investment", "íˆ¬ì"
        ]
        if any(p in query_lower for p in expert_patterns):
            level = ComplexityLevel.EXPERT
            confidence = 0.75
            requires_knowledge = True
        
        # ê¸¸ì´ ê¸°ë°˜ ë³´ì •
        if word_count > 100:
            if level.value < 4:
                level = ComplexityLevel.COMPLEX
        elif word_count > 50:
            if level.value < 3:
                level = ComplexityLevel.MODERATE
        
        return ComplexityAnalysis(
            level=level,
            confidence=confidence,
            reasoning=f"Heuristic analysis based on patterns and length ({word_count} words)",
            recommended_model=self._get_recommended_model(level.value),
            estimated_tokens=min(4000, word_count * 10 + 200),
            requires_tools=requires_tools,
            requires_knowledge=requires_knowledge,
            analysis_time_ms=(time.time() - start_time) * 1000
        )
    
    def _get_recommended_model(self, level: int) -> str:
        """ë³µì¡ë„ì— ë”°ë¥¸ ì¶”ì²œ ëª¨ë¸"""
        model_map = {
            1: "gpt-4o-mini",      # TRIVIAL
            2: "gpt-4o-mini",      # SIMPLE
            3: "claude-3.5-sonnet", # MODERATE
            4: "claude-3.5-sonnet", # COMPLEX
            5: "claude-3-opus",     # EXPERT
        }
        return model_map.get(level, "claude-3.5-sonnet")


class IntelligentRouter:
    """ì§€ëŠ¥í˜• ë¼ìš°í„° (Intelligent Router)
    
    LLM-as-a-Judge íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        judge_model: str = "gpt-4o-mini",
        cost_weight: float = 0.3,
        quality_weight: float = 0.5,
        speed_weight: float = 0.2,
        use_judge_llm: bool = True
    ):
        """ì§€ëŠ¥í˜• ë¼ìš°í„° ì´ˆê¸°í™”
        
        Args:
            judge_model: ë³µì¡ë„ íŒë³„ìš© ëª¨ë¸
            cost_weight: ë¹„ìš© ê°€ì¤‘ì¹˜
            quality_weight: í’ˆì§ˆ ê°€ì¤‘ì¹˜
            speed_weight: ì†ë„ ê°€ì¤‘ì¹˜
            use_judge_llm: Judge LLM ì‚¬ìš© ì—¬ë¶€
        """
        self.judge = JudgeLLM(judge_model) if use_judge_llm else None
        self.cost_weight = cost_weight
        self.quality_weight = quality_weight
        self.speed_weight = speed_weight
        
        # ë¼ìš°íŒ… ì´ë ¥
        self._history: List[RoutingDecision] = []
        
        # ëª¨ë¸ë³„ ì„±ëŠ¥ í†µê³„
        self._model_stats: Dict[str, Dict] = {}
    
    async def route(
        self,
        query: str,
        constraints: Dict[str, Any] = None
    ) -> RoutingDecision:
        """ì¿¼ë¦¬ë¥¼ ìµœì  ëª¨ë¸ë¡œ ë¼ìš°íŒ…
        
        Args:
            query: ì¿¼ë¦¬ ë¬¸ìì—´
            constraints: ì œì•½ ì¡°ê±´ (max_cost, max_latency, preferred_models ë“±)
            
        Returns:
            RoutingDecision: ë¼ìš°íŒ… ê²°ì •
        """
        start_time = time.time()
        constraints = constraints or {}
        
        # 1. ë³µì¡ë„ ë¶„ì„
        if self.judge:
            complexity = await self.judge.analyze(query)
        else:
            # use_judge_llm=Falseì¼ ë•Œ íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ê¸° ì‚¬ìš©
            heuristic_judge = JudgeLLM()
            complexity = heuristic_judge._heuristic_analyze(query, start_time)
        
        # 2. í›„ë³´ ëª¨ë¸ í•„í„°ë§
        candidates = self._filter_candidates(complexity, constraints)
        
        # 3. ìµœì  ëª¨ë¸ ì„ íƒ
        selected_model, fallback_model, strategy = self._select_optimal_model(
            candidates, complexity, constraints
        )
        
        # 4. ë¹„ìš©/ë ˆì´í„´ì‹œ ì¶”ì •
        model_config = MODEL_CONFIGS.get(selected_model)
        if model_config:
            cost_estimate = model_config.calculate_cost(
                complexity.estimated_tokens // 2,
                complexity.estimated_tokens // 2
            )
            latency_estimate = model_config.avg_latency_ms
        else:
            cost_estimate = 0.001
            latency_estimate = 1000
        
        decision = RoutingDecision(
            selected_model=selected_model,
            fallback_model=fallback_model,
            complexity=complexity,
            strategy=strategy,
            cost_estimate=cost_estimate,
            latency_estimate_ms=latency_estimate,
            decision_time_ms=(time.time() - start_time) * 1000
        )
        
        self._history.append(decision)
        
        return decision
    
    def _filter_candidates(
        self,
        complexity: ComplexityAnalysis,
        constraints: Dict[str, Any]
    ) -> List[str]:
        """í›„ë³´ ëª¨ë¸ í•„í„°ë§"""
        candidates = []
        
        max_cost = constraints.get("max_cost_per_query", float("inf"))
        max_latency = constraints.get("max_latency_ms", float("inf"))
        preferred_models = constraints.get("preferred_models", [])
        excluded_models = constraints.get("excluded_models", [])
        
        for model_key, config in MODEL_CONFIGS.items():
            # ì œì™¸ ëª¨ë¸ í•„í„°
            if model_key in excluded_models:
                continue
            
            # ë¹„ìš© í•„í„°
            estimated_cost = config.calculate_cost(500, 500)
            if estimated_cost > max_cost:
                continue
            
            # ë ˆì´í„´ì‹œ í•„í„°
            if config.avg_latency_ms > max_latency:
                continue
            
            # í’ˆì§ˆ í•„í„° (ë³µì¡ë„ì— ë”°ë¼)
            min_quality = {
                ComplexityLevel.TRIVIAL: 6.0,
                ComplexityLevel.SIMPLE: 7.0,
                ComplexityLevel.MODERATE: 7.5,
                ComplexityLevel.COMPLEX: 8.5,
                ComplexityLevel.EXPERT: 9.0,
            }.get(complexity.level, 7.0)
            
            if config.quality_score < min_quality:
                continue
            
            candidates.append(model_key)
        
        # ì„ í˜¸ ëª¨ë¸ ìš°ì„ 
        if preferred_models:
            preferred = [m for m in preferred_models if m in candidates]
            others = [m for m in candidates if m not in preferred_models]
            candidates = preferred + others
        
        return candidates if candidates else ["gpt-4o-mini"]
    
    def _select_optimal_model(
        self,
        candidates: List[str],
        complexity: ComplexityAnalysis,
        constraints: Dict[str, Any]
    ) -> Tuple[str, str, str]:
        """ìµœì  ëª¨ë¸ ì„ íƒ"""
        if not candidates:
            return "gpt-4o-mini", "gpt-3.5-turbo", "fallback"
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
        scores = []
        for model_key in candidates:
            config = MODEL_CONFIGS.get(model_key)
            if not config:
                continue
            
            # ì •ê·œí™”ëœ ì ìˆ˜ (0-1)
            quality_score = config.quality_score / 10.0
            cost_score = 1.0 - min(1.0, config.input_cost_per_1k / 0.02)  # ë¹„ìš© ì—­ìˆ˜
            speed_score = 1.0 - min(1.0, config.avg_latency_ms / 5000)   # ë ˆì´í„´ì‹œ ì—­ìˆ˜
            
            # ë³µì¡ë„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
            if complexity.level in [ComplexityLevel.EXPERT, ComplexityLevel.COMPLEX]:
                # ë³µì¡í•œ ì‘ì—…: í’ˆì§ˆ ìš°ì„ 
                adjusted_quality_weight = self.quality_weight * 1.3
                adjusted_cost_weight = self.cost_weight * 0.7
            elif complexity.level in [ComplexityLevel.TRIVIAL, ComplexityLevel.SIMPLE]:
                # ê°„ë‹¨í•œ ì‘ì—…: ë¹„ìš©/ì†ë„ ìš°ì„ 
                adjusted_quality_weight = self.quality_weight * 0.7
                adjusted_cost_weight = self.cost_weight * 1.3
            else:
                adjusted_quality_weight = self.quality_weight
                adjusted_cost_weight = self.cost_weight
            
            total_score = (
                quality_score * adjusted_quality_weight +
                cost_score * adjusted_cost_weight +
                speed_score * self.speed_weight
            )
            
            scores.append((model_key, total_score))
        
        # ì •ë ¬
        scores.sort(key=lambda x: x[1], reverse=True)
        
        selected = scores[0][0] if scores else "gpt-4o-mini"
        fallback = scores[1][0] if len(scores) > 1 else "gpt-3.5-turbo"
        
        # ì „ëµ ê²°ì •
        strategy = "balanced"
        if self.quality_weight > 0.6:
            strategy = "quality_first"
        elif self.cost_weight > 0.5:
            strategy = "cost_optimized"
        elif self.speed_weight > 0.4:
            strategy = "speed_first"
        
        return selected, fallback, strategy
    
    def get_routing_history(self, limit: int = 100) -> List[RoutingDecision]:
        """ë¼ìš°íŒ… ì´ë ¥ ì¡°íšŒ"""
        return self._history[-limit:]
    
    def get_statistics(self) -> Dict[str, Any]:
        """ë¼ìš°íŒ… í†µê³„"""
        if not self._history:
            return {"message": "No routing history"}
        
        model_counts = {}
        complexity_counts = {}
        total_cost = 0
        total_latency = 0
        
        for decision in self._history:
            model_counts[decision.selected_model] = model_counts.get(decision.selected_model, 0) + 1
            complexity_counts[decision.complexity.level.name] = complexity_counts.get(decision.complexity.level.name, 0) + 1
            total_cost += decision.cost_estimate
            total_latency += decision.latency_estimate_ms
        
        return {
            "total_routings": len(self._history),
            "model_distribution": model_counts,
            "complexity_distribution": complexity_counts,
            "total_estimated_cost": total_cost,
            "avg_estimated_latency": total_latency / len(self._history) if self._history else 0
        }


# === í…ŒìŠ¤íŠ¸ ===
async def test_intelligent_router():
    """ì§€ëŠ¥í˜• ë¼ìš°í„° í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("ğŸ§  Intelligent Router Test (LLM-as-a-Judge)")
    print("=" * 60)
    
    router = IntelligentRouter(use_judge_llm=False)  # íœ´ë¦¬ìŠ¤í‹± ëª¨ë“œ
    
    test_queries = [
        "Translate 'hello' to Korean",               # TRIVIAL
        "What is the capital of France?",            # SIMPLE
        "Explain how neural networks work",          # MODERATE
        "Write a Python algorithm for quicksort",    # COMPLEX
        "Design a microservices architecture for a banking system", # EXPERT
    ]
    
    for query in test_queries:
        decision = await router.route(query)
        
        print(f"\nğŸ“ Query: {query[:50]}...")
        print(f"   Complexity: {decision.complexity.level.name} ({decision.complexity.confidence:.0%})")
        print(f"   Selected: {decision.selected_model}")
        print(f"   Fallback: {decision.fallback_model}")
        print(f"   Strategy: {decision.strategy}")
        print(f"   Est. Cost: ${decision.cost_estimate:.6f}")
        print(f"   Decision Time: {decision.decision_time_ms:.1f}ms")
    
    # í†µê³„
    print("\n" + "=" * 60)
    print("ğŸ“Š Routing Statistics")
    print("=" * 60)
    stats = router.get_statistics()
    print(f"   Model Distribution: {stats['model_distribution']}")
    print(f"   Complexity Distribution: {stats['complexity_distribution']}")
    
    print("\nâœ… Intelligent Router Test Complete!")


if __name__ == "__main__":
    asyncio.run(test_intelligent_router())
